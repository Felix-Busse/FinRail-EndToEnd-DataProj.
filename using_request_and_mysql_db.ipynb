{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd4de6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crontab import CronTab\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import select, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import strftime\n",
    "import timeit\n",
    "\n",
    "# Add path of subdirectory containing own modules\n",
    "modules_path = os.path.join(os.getcwd(), 'data_collect_app')\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "\n",
    "import finrail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08dceda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 14:21:11.623123: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-07 14:21:11.623160: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-07 14:21:11.628688: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# Define directory for tensorboard log files\n",
    "def dir_logs(parent_dir='tf_log'):\n",
    "    return Path(parent_dir) / strftime('%Y_%m_%d_%H_%M_%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9c33d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tweak_train(df_):\n",
    "    '''Function takes DataFrame as returned from SQL-query and returns processed DataFrame\n",
    "    Transformations:\n",
    "        - DataType: update to all columns\n",
    "        - Introducing columns \"commuter\" and \"long_distance\" by grouping by date and train category\n",
    "          and then unstacking ones\n",
    "        - pushing the date information from index to own column\n",
    "        - Renaming and setting back nested column names\n",
    "        \n",
    "    '''\n",
    "    return (df_\n",
    "    .astype({\n",
    "        'date': 'datetime64',\n",
    "        'train_cat': 'category',\n",
    "        'total_length': np.float32\n",
    "    })\n",
    "    .groupby(['date', 'train_cat'])\n",
    "    .max().unstack()\n",
    "    .reset_index()\n",
    "    .set_axis(['date', 'commuter', 'long_distance'], axis=1)\n",
    "           )\n",
    "\n",
    "# Open fire and read stored SQL query to variable\n",
    "with open('sql_query.txt', 'r') as w:\n",
    "    sql_query_str = w.read()\n",
    "    \n",
    "# Open SQL connection and send query. This query will:\n",
    "# 1. Sum length of all wagon in a journey section\n",
    "# 2. Choose maximum length of all wagons among journey sections for each train\n",
    "# 3. Sum length of wagons for all trains per day, grouped by train category (Commuter, Long-distance)\n",
    "with engine.connect() as connection:\n",
    "    df = pd.read_sql_query(text(sql_query_str), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb08babf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             datetime64[ns]\n",
       "commuter                float32\n",
       "long_distance           float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates tables in finrail db, returns database engine\n",
    "engine = finrail_db.create_tables(db_str='mysql+mysqlconnector://root:admin123@localhost:5000/finrail')\n",
    "# Apply tweak_train to output of SQL query to obtain desired time series\n",
    "df = tweak_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db9dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_window(data, seq_length, shift=1, stride=1):\n",
    "    '''Function takes dataset and returns dataset containing windows with data from input dataset.\n",
    "    Parameters:\n",
    "        data <tf.data.Dataset> input dataset\n",
    "        seq_length <int> defines length of windows in output dataset\n",
    "        shift <int> defines how many time steps of gap are between two consecutive windows\n",
    "        stride <int> defines how many time steps are between two consecutive output data points\n",
    "        \n",
    "    Return:\n",
    "        <tf.data.Dataset> Dataset containing windows of seq_length based on input dataset data\n",
    "    '''\n",
    "    data = data.window(size=seq_length, shift=shift, stride=stride, drop_remainder=True)\n",
    "    data = data.flat_map(lambda x: x) # flatten nested Dataset structure returned by .window()\n",
    "    return data.batch(seq_length) # batch of size seq_length will give one window in each batch\n",
    "\n",
    "def timeseries_dataset_seq2seq(data, forecast_length=1, seq_length=7):\n",
    "    '''Function takes Dataset and returns Dataset with windows suitable to train a \n",
    "    sequence to sequence RNN\n",
    "    Parameters:\n",
    "        data <tf.data.Dataset> input dataset\n",
    "        forecast_length <int> number of time steps to be forecasted into the future\n",
    "        seq_length <int> length of sequences fed to RNN (number of consecutive time steps \n",
    "        in one training instance)\n",
    "    '''\n",
    "    data = timeseries_window(data, forecast_length+1) # First dimension one time step longer than\n",
    "                                                      # forecast_length, as targets are generated as well\n",
    "    data = timeseries_window(data, seq_length) # Second dimension consists of windows of size sequence length\n",
    "    return data.map(lambda x: (x[:, 0], x[:, 1:])) # map to tuple (training instance, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d79e28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set until 2020 including, scaling down training data by a factor of 1E5\n",
    "commuter_train = tf.data.Dataset.from_tensor_slices(df['commuter'][:1847].values / 1E5) \n",
    "#creating sequences and targets for training\n",
    "commuter_train = timeseries_dataset_seq2seq(commuter_train, 14, 30)\n",
    "# cache dataset to avoid previos calculation to be done every epoch during training\n",
    "commuter_train = commuter_train.cache()\n",
    "# Shuffle training data, reshuffling after every epoch for better convergence\n",
    "commuter_train = commuter_train.shuffle(500, seed=42, reshuffle_each_iteration=True)\n",
    "# Batch training data \n",
    "commuter_train = commuter_train.batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f5bf3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer stack that defines input shape and will scale down inputs by a factor of 1E5\n",
    "input_processing = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    tf.keras.layers.Normalization(mean=0, variance=1E10)\n",
    "])\n",
    "\n",
    "#Output layer that will scale up predictions by a factor of 1E5\n",
    "output_processing = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(mean=0, variance=1E-10)\n",
    "])\n",
    "\n",
    "#RNN laer stack for a sequence to sequence model for univariate time series\n",
    "rnn_seq2seq = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(14, activation='linear')  \n",
    "])\n",
    "\n",
    "#Complete model including Input, Output and RNN layer stacks\n",
    "rnn_seq2seq_complete = tf.keras.Sequential([\n",
    "    input_processing,\n",
    "    rnn_seq2seq,\n",
    "    output_processing\n",
    "])\n",
    "\n",
    "#Model used during training, to avoid calculating scaling on every iteration\n",
    "rnn_seq2seq_training = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    rnn_seq2seq\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c2ad7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 14:26:26.461721: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-07 14:26:26.461761: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-07 14:26:26.463046: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 11ms/step - loss: 0.0097\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.0098\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 14:26:29.470059: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-07 14:26:29.470090: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-07 14:26:29.493162: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-03-07 14:26:29.498201: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0097\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0097\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0097\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0097\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0097\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0096\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0097\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0097\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0096\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0096\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0097\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.0096\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0096\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0096\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0096\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0096\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0095\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0095\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0096\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0095\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0095\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0095\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0095\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0095\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0095\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0095\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0094\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0095\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.0095\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0094\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0094\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0094\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0094\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0094\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.0094\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.0095\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0093\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0093\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.0093\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0093\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1ccc985030>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define callback for Tensorboard update\n",
    "current_dir = dir_logs()\n",
    "callback_tensorboard = tf.keras.callbacks.TensorBoard(current_dir, profile_batch=100)\n",
    "\n",
    "rnn_seq2seq_training.compile(optimizer='adam', loss='mse')\n",
    "rnn_seq2seq_training.fit(commuter_train, epochs = 50, callbacks=[callback_tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6eef1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[89215.28 , 54716.67 , 49396.44 , 84032.18 , 96815.91 , 86950.54 ,\n",
       "        91648.24 , 87465.06 , 54566.914, 49603.492, 83723.25 , 98576.27 ,\n",
       "        86204.13 , 91678.1  ]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rnn_seq2seq.predict(a)\n",
    "result[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "347338a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commuter_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e2f8f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 30, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Tensor()\n",
    "for i, (train, target) in enumerate(commuter_train):\n",
    "    a = train\n",
    "    if i > 2:\n",
    "        break\n",
    "a = a[0, :]\n",
    "a = a[np.newaxis, :, np.newaxis]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ee27c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 12ms/step\n",
      "6377.252864\n",
      "6401.092608\n",
      "6634.546688\n",
      "6466.147328\n",
      "6719.310848\n",
      "6609.618432\n",
      "6410.134016\n",
      "6175.944704\n",
      "7012.801024\n",
      "7358.948864\n",
      "6293.075456\n",
      "1215.83744\n",
      "\n",
      "\n",
      "2431.67488\n"
     ]
    }
   ],
   "source": [
    "commuter_test = tf.data.Dataset.from_tensor_slices(df['commuter'][1847:]) # Data from 2021 onwards\n",
    "#commuter_test = timeseries_window(commuter_test, 60)\n",
    "#j = int(0)\n",
    "#a = 0\n",
    "#for i in commuter_test.as_numpy_iterator():\n",
    "#    if (j < 2):\n",
    "#        print(rnn_seq2seq(i[np.newaxis, :, np.newaxis].copy()).shape)\n",
    "#    j += 1\n",
    "\n",
    "def eval_seq2seq_model(model, data, forecast_length=1, seq_length=7, batch_size=100):\n",
    "    data = timeseries_window(data, forecast_length+seq_length)\n",
    "    data = data.map(lambda x: (x[:seq_length], x[seq_length:]))\n",
    "\n",
    "    data = data.batch(batch_size)\n",
    "    # Predict and keep only last sequence of prediction\n",
    "    prediction = tf.data.Dataset.from_tensor_slices(rnn_seq2seq.predict(data)[:, -1, :])\n",
    "    prediction = prediction.batch(batch_size)\n",
    "    data = tf.data.Dataset.zip(data, prediction)\n",
    "    mse = np.zeros(14, dtype=np.float32)\n",
    "    for i in data.as_numpy_iterator():\n",
    "        sequences, target = i[0]\n",
    "        pred = i[1]\n",
    "        mse = np.sum(np.square(pred - target), axis=0) / batch_size\n",
    "        print(mse[0]/1E6)\n",
    "        mse += mse\n",
    "    print('\\n')\n",
    "    print(mse[0]/1E6)\n",
    "    #for i in data.as_numpy_iterator():\n",
    "    #    result = rnn_seq2seq(i[0][:, :, np.newaxis])\n",
    "    #    target = i[1][:, np.newaxis, :]\n",
    "    #    print(result[0, -1, :] - target[0, :, :])\n",
    "    #    print(np.sqrt(np.sum(np.square(result[:, -1, :] - target)) / batch_size / forecast_length))\n",
    "\n",
    "eval_seq2seq_model(rnn_seq2seq_complete, commuter_test, forecast_length=14, seq_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e215421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "493/493 [==============================] - 3s 2ms/step - loss: 0.2131\n",
      "Epoch 2/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.1121\n",
      "Epoch 3/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0919\n",
      "Epoch 4/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0881\n",
      "Epoch 5/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0871\n",
      "Epoch 6/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0866\n",
      "Epoch 7/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0862\n",
      "Epoch 8/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0859\n",
      "Epoch 9/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0856\n",
      "Epoch 10/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f83c8841f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    tf.keras.layers.LSTM(3, return_sequences=True)\n",
    "])\n",
    "test_rnn.compile(loss='mse', optimizer='adam')\n",
    "x_training_data = np.random.rand(500, 1)\n",
    "x_train = tf.data.Dataset.from_tensor_slices(x_training_data)\n",
    "x_train = timeseries_dataset_seq2seq(x_train)\n",
    "y_training_data = np.random.rand(500, 3)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_training_data)\n",
    "\n",
    "\n",
    "test_rnn.fit(x=x_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bf8dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 60, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rnn.predict(np.random.rand(1, 10, 1))\n",
    "np.random.rand(1, 60, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "25804b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67388077 0.18984745 0.61122116 0.31137044 0.50503867 0.18929037\n",
      " 0.61636287 0.97836272 0.70692446 0.79188471 0.11336993 0.01475838\n",
      " 0.83786145 0.50861334]\n",
      "[0.81867838 0.79164872 0.11088158 0.29023907 0.57815831 0.0342671\n",
      " 0.00434693 0.2741532  0.15625099 0.78368318 0.18649465 0.0013391\n",
      " 0.85996041 0.29445972]\n",
      "[0.01330934 0.24549398 0.08873156 0.71743076 0.21148537 0.72991601\n",
      " 0.66889605 0.83391747 0.81458398 0.35312731 0.35237431 0.73738273\n",
      " 0.96517253 0.52211691]\n",
      "[0.08045153 0.92695746 0.30384688 0.22169256 0.85231981 0.36898274\n",
      " 0.69632564 0.17785737 0.99774497 0.93419654 0.98740287 0.81108123\n",
      " 0.90829649 0.51305405]\n",
      "[0.23834562 0.90531048 0.00863958 0.08093868 0.22606262 0.85072973\n",
      " 0.22908413 0.73069026 0.762691   0.32499139 0.65763599 0.64558172\n",
      " 0.69650676 0.10202842]\n",
      "[0.60028532 0.07613098 0.38184849 0.11085824 0.82751313 0.58460833\n",
      " 0.13727838 0.87527711 0.51458954 0.46814201 0.28440379 0.12228945\n",
      " 0.7698344  0.23207313]\n",
      "[0.32205817 0.39806014 0.68102314 0.28397828 0.01403007 0.12466031\n",
      " 0.54509912 0.32188899 0.5034985  0.07103297 0.02632227 0.62627549\n",
      " 0.84521944 0.96162737]\n",
      "[0.44964945 0.96535731 0.87818486 0.18301416 0.01080452 0.61278645\n",
      " 0.3238817  0.61165894 0.64247133 0.05489187 0.58672332 0.8481531\n",
      " 0.56085074 0.71518759]\n",
      "[0.81144944 0.81255406 0.76585015 0.0167234  0.00834109 0.75603269\n",
      " 0.86140576 0.06015929 0.40342788 0.72729481 0.03530758 0.94190276\n",
      " 0.67229717 0.57643199]\n",
      "[0.64400356 0.13655128 0.8332986  0.0185449  0.26777481 0.27449127\n",
      " 0.28898543 0.72502415 0.09113105 0.92011646 0.67805378 0.75153067\n",
      " 0.29665466 0.10618037]\n",
      "[0.47346333 0.44613342 0.6044283  0.79513136 0.33243857 0.98734486\n",
      " 0.66060642 0.93425082 0.4561239  0.59600395 0.69138945 0.68268566\n",
      " 0.04714791 0.34924071]\n",
      "[0.54915037 0.82230529 0.64303598 0.73797224 0.09874984 0.06138457\n",
      " 0.2170812  0.61995817 0.52351431 0.83639597 0.25606677 0.94474034\n",
      " 0.00423285 0.36990968]\n",
      "[0.62916207 0.70845953 0.83946539 0.7509079  0.4371796  0.37972269\n",
      " 0.35942954 0.41287582 0.80661376 0.92173137 0.05422665 0.37877763\n",
      " 0.02521917 0.61325941]\n",
      "[0.02576389 0.88670677 0.54250339 0.10641117 0.34866735 0.76156822\n",
      " 0.30287355 0.17971638 0.04822514 0.28855145 0.30267054 0.5301505\n",
      " 0.13835105 0.55968984]\n",
      "[0.33798793 0.94066733 0.91183926 0.83931707 0.12657836 0.65554698\n",
      " 0.73708292 0.53919446 0.38122131 0.12838358 0.08115912 0.04670611\n",
      " 0.26665036 0.7523315 ]\n",
      "[0.71751975 0.44699908 0.4507161  0.02535093 0.53020273 0.82665169\n",
      " 0.39056484 0.04085058 0.44936695 0.11198516 0.59320776 0.64680055\n",
      " 0.48264001 0.09088077]\n",
      "[0.39052736 0.03771287 0.13764596 0.05873553 0.00851029 0.28863883\n",
      " 0.34525324 0.98827033 0.57798653 0.59622998 0.91635766 0.88961131\n",
      " 0.62788677 0.03113455]\n",
      "[0.83743507 0.87310166 0.21002915 0.02451076 0.87502626 0.09527334\n",
      " 0.80994109 0.46896117 0.43009102 0.06232755 0.62440147 0.96058492\n",
      " 0.40201056 0.10517127]\n",
      "[0.77084595 0.84287741 0.4210406  0.00367403 0.16589142 0.03233794\n",
      " 0.36606983 0.12638273 0.39014338 0.3828352  0.26918524 0.46302582\n",
      " 0.6690314  0.09478815]\n",
      "[0.44857359 0.54856402 0.9969665  0.02840385 0.61707052 0.9906487\n",
      " 0.08636966 0.93316015 0.37327439 0.03458469 0.96864453 0.45429053\n",
      " 0.66135642 0.82112224]\n",
      "[0.88896954 0.93742543 0.72018904 0.91407235 0.90929593 0.59886644\n",
      " 0.51157176 0.93264991 0.72604191 0.68102092 0.22363341 0.35087806\n",
      " 0.43813092 0.0841    ]\n",
      "[0.52491029 0.32967699 0.09620995 0.67936254 0.10820112 0.75912062\n",
      " 0.16849995 0.55112123 0.47437068 0.36422081 0.02548628 0.90185522\n",
      " 0.3896367  0.47442485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.24642  , 13.268541 , 11.237595 ,  7.1986403,  8.0593405,\n",
       "       10.96287  ,  9.327009 , 12.3163805, 11.230288 , 10.433632 ,\n",
       "        8.914517 , 12.7504015, 11.564948 ,  8.877827 ], dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(14, dtype=np.float32)\n",
    "\n",
    "for i in range(22):\n",
    "    b = np.random.rand(14)\n",
    "    a += b\n",
    "    print(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae57b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This blocks evaluates all possible keys in the nested dictionary \"wagon\" in compositions of one day\n",
    "\n",
    "properties_dict = dict()\n",
    "for train in k.json():\n",
    "    for journey in (train['journeySections']):\n",
    "        for wagon in journey['wagons']:\n",
    "            for i, prop in enumerate(wagon.keys()):\n",
    "                try:\n",
    "                    properties_dict[prop]\n",
    "                except:\n",
    "                    properties_dict[prop] = prop\n",
    "print(properties_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6376e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84644132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "session.add(bsp)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e2ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as w:\n",
    "    w.write('haha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c57c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
