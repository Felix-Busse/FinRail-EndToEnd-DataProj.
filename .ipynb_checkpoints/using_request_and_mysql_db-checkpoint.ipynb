{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4de6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 10:13:53.892294: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 10:13:53.938562: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 10:13:53.939309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 10:13:54.796090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from crontab import CronTab\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import select, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import strftime\n",
    "import timeit\n",
    "\n",
    "# Add path of subdirectory containing own modules\n",
    "modules_path = os.path.join(os.getcwd(), 'data_collect_app')\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "\n",
    "import finrail_db\n",
    "\n",
    "# Load tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08dceda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory for tensorboard log files\n",
    "def dir_logs(parent_dir='tf_log'):\n",
    "    return Path(parent_dir) / strftime('%Y_%m_%d_%H_%M_%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9c33d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tweak_train(df_):\n",
    "    '''Function takes DataFrame as returned from SQL-query and returns processed DataFrame\n",
    "    Transformations:\n",
    "        - DataType: update to all columns\n",
    "        - Introducing columns \"commuter\" and \"long_distance\" by grouping by date and train category\n",
    "          and then unstacking ones\n",
    "        - pushing the date information from index to own column\n",
    "        - Renaming and setting back nested column names\n",
    "        \n",
    "    '''\n",
    "    return (df_\n",
    "    .astype({\n",
    "        'date': 'datetime64',\n",
    "        'train_cat': 'category',\n",
    "        'total_length': np.float32\n",
    "    })\n",
    "    .groupby(['date', 'train_cat'])\n",
    "    .max().unstack()\n",
    "    .reset_index()\n",
    "    .set_axis(['date', 'commuter', 'long_distance'], axis=1)\n",
    "           )\n",
    "# Creates tables in finrail db, returns database engine\n",
    "engine = finrail_db.create_tables(db_str='mysql+mysqlconnector://root:admin123@localhost:5000/finrail')\n",
    "\n",
    "# Open fire and read stored SQL query to variable\n",
    "with open('sql_query.txt', 'r') as w:\n",
    "    sql_query_str = w.read()\n",
    "    \n",
    "# Open SQL connection and send query. This query will:\n",
    "# 1. Sum length of all wagon in a journey section\n",
    "# 2. Choose maximum length of all wagons among journey sections for each train\n",
    "# 3. Sum length of wagons for all trains per day, grouped by train category (Commuter, Long-distance)\n",
    "with engine.connect() as connection:\n",
    "    df = pd.read_sql_query(text(sql_query_str), connection)\n",
    "\n",
    "# Apply tweak_train to output of SQL query to obtain desired time series\n",
    "df = tweak_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7db9dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_window(data, seq_length, shift=1, stride=1):\n",
    "    '''Function takes dataset and returns dataset containing windows with data from input dataset.\n",
    "    Parameters:\n",
    "        data <tf.data.Dataset> input dataset\n",
    "        seq_length <int> defines length of windows in output dataset\n",
    "        shift <int> defines how many time steps of gap are between two consecutive windows\n",
    "        stride <int> defines how many time steps are between two consecutive output data points\n",
    "        \n",
    "    Return:\n",
    "        <tf.data.Dataset> Dataset containing windows of seq_length based on input dataset data\n",
    "    '''\n",
    "    data = data.window(size=seq_length, shift=shift, stride=stride, drop_remainder=True)\n",
    "    data = data.flat_map(lambda x: x) # flatten nested Dataset structure returned by .window()\n",
    "    return data.batch(seq_length) # batch of size seq_length will give one window in each batch\n",
    "\n",
    "def timeseries_dataset_seq2seq(data, forecast_length=1, seq_length=7):\n",
    "    '''Function takes Dataset and returns Dataset with windows suitable to train a \n",
    "    sequence to sequence RNN\n",
    "    Parameters:\n",
    "        data <tf.data.Dataset> input dataset\n",
    "        forecast_length <int> number of time steps to be forecasted into the future\n",
    "        seq_length <int> length of sequences fed to RNN (number of consecutive time steps \n",
    "        in one training instance)\n",
    "    '''\n",
    "    data = timeseries_window(data, forecast_length+1) # First dimension one time step longer than\n",
    "                                                      # forecast_length, as targets are generated as well\n",
    "    data = timeseries_window(data, seq_length) # Second dimension consists of windows of size sequence length\n",
    "    return data.map(lambda x: (x[:, 0], x[:, 1:])) # map to tuple (training instance, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d79e28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_dataset(df_, column, row_split, forecast_length=14, seq_length=30, \n",
    "                             batch_size=32, seed=42, reshuffle_each_iteration=True):\n",
    "    '''Function takes Dataframe and returns tf.data.Dataset with specs:\n",
    "    Parameters:\n",
    "        df_ <pd.Dataframe> Dataframe with time series data (np.float32) in columns\n",
    "        column <string> name of column in DataFrame to use\n",
    "        row_split <tuple of two int> defines row index between data is extracted from df_\n",
    "        forecast_length <int> number of time steps to be forecasted into the future\n",
    "        seq_length <int> length of sequences fed to RNN (number of consecutive time steps \n",
    "        batch_size <int> batch_size of returned Dataset\n",
    "        seed <int> random seed for shuffling data\n",
    "        reshuffle_each_iteration <boolean> Defines wheater Dataset is ot be reshuffled after each\n",
    "        training epoch\n",
    "    Return:\n",
    "        <tf.data.Dataset> ready to feed to .fit() of an sequence to sequence RNN\n",
    "    '''\n",
    "    data = tf.data.Dataset.from_tensor_slices(df[column][:1847].values / 1E5)\n",
    "    data = timeseries_dataset_seq2seq(data, forecast_length, seq_length)\n",
    "    data = data.cache() # cache, so that previous transformation are only performed ones\n",
    "    #data = data.shuffle(500, seed=seed, reshuffle_each_iteration=reshuffle_each_iteration)\n",
    "    return data.batch(batch_size=batch_size).prefetch(1)\n",
    "\n",
    "#training set until 2020 including\n",
    "commuter_train = prepare_training_dataset(df, 'commuter', (0, 1847))\n",
    "#validation set from 2021 to 2022 including\n",
    "commuter_val = prepare_training_dataset(df, 'commuter', (1847, 2577), \n",
    "                                        batch_size=200, reshuffle_each_iteration=False)\n",
    "#test set from 2023 to 2024-03-06\n",
    "commuter_test = prepare_training_dataset(df, 'commuter', (2577, 3008), \n",
    "                                        batch_size=200, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f5bf3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer stack that defines input shape and will scale down inputs by a factor of 1E5\n",
    "input_processing = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    tf.keras.layers.Normalization(mean=0, variance=1E10)\n",
    "])\n",
    "\n",
    "#Output layer that will scale up predictions by a factor of 1E5\n",
    "output_processing = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(mean=0, variance=1E-10)\n",
    "])\n",
    "\n",
    "#RNN laer stack for a sequence to sequence model for univariate time series\n",
    "rnn_seq2seq = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(14, activation='linear')  \n",
    "])\n",
    "\n",
    "#Complete model including Input, Output and RNN layer stacks\n",
    "rnn_seq2seq_complete = tf.keras.Sequential([\n",
    "    input_processing,\n",
    "    rnn_seq2seq,\n",
    "    output_processing\n",
    "])\n",
    "\n",
    "#Model used during training, to avoid calculating scaling on every iteration\n",
    "rnn_seq2seq_training = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    rnn_seq2seq\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e944953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-82d5929de7925315\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-82d5929de7925315\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c2ad7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "    634/Unknown - 55s 30ms/step - loss: 0.0092 - custom_metric: 30.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5E-3\u001b[39m)\n\u001b[1;32m      6\u001b[0m rnn_seq2seq_training\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[custom_metric])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrnn_seq2seq_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommuter_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommuter_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback_tensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, verbose=0)\u001b[39;00m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define callback for Tensorboard update\n",
    "current_dir = dir_logs()\n",
    "callback_tensorboard = tf.keras.callbacks.TensorBoard(current_dir, histogram_freq=5)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5E-3)\n",
    "rnn_seq2seq_training.compile(optimizer=optimizer, loss='mse', metrics=[custom_metric])\n",
    "rnn_seq2seq_training.fit(commuter_train, validation_data=commuter_val, \n",
    "                         epochs = 200, callbacks=[callback_tensorboard])#, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6eef1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    return tf.cast(tf.shape(y_true[-1, :])[0], np.float32)\n",
    "    #return (tf.reduce_sum(tf.math.square(y_true[-1, :] - y_pred[-1, :])) \n",
    "    #        / tf.cast(tf.shape(y_true)[0], np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "347338a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.514296  , 0.396632  , 0.84542   , 0.840988  , 0.849374  ,\n",
      "       0.843996  , 0.840372  , 0.514296  , 0.39888802, 0.83998   ,\n",
      "       0.83426   , 0.8147    , 0.80659604, 0.83964396], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.89841   , 0.894234  , 0.557528  , 0.423568  , 0.88349795,\n",
      "       0.896802  , 0.901806  , 0.90187794, 0.90909   , 0.562284  ,\n",
      "       0.41448802, 0.8822    , 0.892186  , 0.89222   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.363614  , 0.79706   , 0.7955    , 0.793966  , 0.344518  ,\n",
      "       0.288142  , 0.35942   , 0.362026  , 0.80396396, 0.802948  ,\n",
      "       0.79773396, 0.792576  , 0.382896  , 0.49272   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.74922603, 0.4958    , 0.35984   , 0.74884   , 0.75616604,\n",
      "       0.740184  , 0.76503396, 0.677056  , 0.475842  , 0.360298  ,\n",
      "       0.771156  , 0.79605794, 0.77513   , 0.774054  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.89334   , 0.89607203, 0.890554  , 0.807666  , 0.53477603,\n",
      "       0.47932   , 0.89292204, 0.892506  , 0.891706  , 0.500632  ,\n",
      "       0.888574  , 0.54024804, 0.41122398, 0.88745   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.78373796, 0.789288  , 0.773584  , 0.78093797, 0.49516   ,\n",
      "       0.369976  , 0.76264   , 0.74724   , 0.72895604, 0.763072  ,\n",
      "       0.49546802, 0.36964   , 0.37106398, 0.7422    ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.37106398, 0.7422    , 0.740704  , 0.69255203, 0.73615205,\n",
      "       0.745964  , 0.48989603, 0.37428   , 0.76481795, 0.76572   ,\n",
      "       0.76796   , 0.725012  , 0.7619    , 0.49816802], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.79813397, 0.49272   , 0.362522  , 0.79114795, 0.800606  ,\n",
      "       0.80494   , 0.806572  , 0.767072  , 0.49037802, 0.34548   ,\n",
      "       0.80478   , 0.7723    , 0.79264396, 0.80704397], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.89815396, 0.856754  , 0.894278  , 0.541     , 0.413144  ,\n",
      "       0.894008  , 0.900986  , 0.898788  , 0.907856  , 0.558504  ,\n",
      "       0.428736  , 0.429072  , 0.90252   , 0.889736  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.52028   , 0.41088802, 0.86001396, 0.848434  , 0.86121   ,\n",
      "       0.865306  , 0.85463   , 0.34153   , 0.295008  , 0.40562397,\n",
      "       0.86269206, 0.866366  , 0.85763794, 0.81676203], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.90327203, 0.90486205, 0.562014  , 0.43262398, 0.90477604,\n",
      "       0.893912  , 0.90436   , 0.86224794, 0.90176797, 0.557416  ,\n",
      "       0.439056  , 0.898888  , 0.902856  , 0.90544796], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.934268  , 0.93845797, 0.921184  , 0.93572   , 0.940312  ,\n",
      "       0.58570397, 0.448488  , 0.929698  , 0.934088  , 0.94044   ,\n",
      "       0.931752  , 0.940104  , 0.584408  , 0.446368  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.35942   , 0.362026  , 0.80396396, 0.802948  , 0.79773396,\n",
      "       0.792576  , 0.382896  , 0.49272   , 0.361444  , 0.780898  ,\n",
      "       0.78344   , 0.357708  , 0.737806  , 0.714888  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.49516   , 0.3736    , 0.805264  , 0.803996  , 0.7999    ,\n",
      "       0.80423206, 0.80282795, 0.495912  , 0.37254   , 0.79583204,\n",
      "       0.803244  , 0.80098796, 0.80057204, 0.80057204], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.795736  , 0.80032796, 0.80016   , 0.78262   , 0.79832   ,\n",
      "       0.49816802, 0.37557602, 0.831362  , 0.81480396, 0.82858604,\n",
      "       0.82556796, 0.834972  , 0.514296  , 0.400312  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.79948395, 0.80358   , 0.49516   , 0.3736    , 0.805264  ,\n",
      "       0.803996  , 0.7999    , 0.80423206, 0.80282795, 0.495912  ,\n",
      "       0.37254   , 0.79583204, 0.803244  , 0.80098796], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.8992    , 0.91605204, 0.603332  , 0.452068  , 0.901944  ,\n",
      "       0.90661436, 0.90530205, 0.88893205, 0.907472  , 0.59439397,\n",
      "       0.44914   , 0.92075795, 0.907788  , 0.915608  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.3736    , 0.805264  , 0.803996  , 0.7999    , 0.80423206,\n",
      "       0.80282795, 0.495912  , 0.37254   , 0.79583204, 0.803244  ,\n",
      "       0.80098796, 0.80057204, 0.80057204, 0.49516   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.889498  , 0.89401   , 0.940426  , 0.69876   , 0.45468   ,\n",
      "       0.89295   , 0.89089   , 0.89815396, 0.856754  , 0.894278  ,\n",
      "       0.541     , 0.413144  , 0.894008  , 0.900986  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.95474   , 0.58258396, 0.484484  , 1.011448  , 0.66026396,\n",
      "       0.94644   , 0.95271397, 0.96148   , 0.590104  , 0.48476398,\n",
      "       0.94783604, 0.946468  , 0.954276  , 0.48598802], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.4717    , 0.92839205, 0.92839205, 0.932266  , 0.93142796,\n",
      "       0.92789   , 0.56132   , 0.46794   , 0.937142  , 0.93256795,\n",
      "       0.933864  , 0.940008  , 0.937766  , 0.570552  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.40938398, 0.892506  , 0.893466  , 0.89401   , 0.89388204,\n",
      "       0.41464   , 0.65680796, 0.481992  , 0.410136  , 0.89398205,\n",
      "       0.89401   , 0.893746  , 0.896074  , 0.541752  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.41205603, 0.887862  , 0.892252  , 0.893394  , 0.89130604,\n",
      "       0.895932  , 0.541     , 0.410136  , 0.89130604, 0.89334   ,\n",
      "       0.89607203, 0.890554  , 0.807666  , 0.53477603], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.931618  , 0.938338  , 0.92967796, 0.92663795, 0.562728  ,\n",
      "       0.47248   , 0.92184204, 0.92158604, 0.92313   , 0.92321396,\n",
      "       0.93282   , 0.561068  , 0.47248   , 0.935058  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.92549604, 0.93001395, 0.928118  , 0.932248  , 0.93098396,\n",
      "       0.560552  , 0.470848  , 0.931046  , 0.929512  , 0.92725205,\n",
      "       0.92745   , 0.94086   , 0.56436   , 0.475616  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.893746  , 0.896074  , 0.541752  , 0.40904802, 0.890058  ,\n",
      "       0.893746  , 0.86256206, 0.89072204, 0.900026  , 0.547016  ,\n",
      "       0.418744  , 0.626128  , 0.892958  , 0.892506  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.47344   , 0.933208  , 0.936716  , 0.933886  , 0.932898  ,\n",
      "       0.944164  , 0.591524  , 0.49177   , 0.940736  , 0.918548  ,\n",
      "       0.92721397, 0.926296  , 0.93479604, 0.45683601], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.94453204, 0.94371206, 0.94275   , 0.94375396, 0.57388   ,\n",
      "       0.480752  , 0.94102   , 0.94481397, 0.94472206, 0.94107604,\n",
      "       0.943914  , 0.57714397, 0.480752  , 0.937622  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.94261205, 0.574968  , 0.47924802, 0.93258   , 0.933446  ,\n",
      "       0.941416  , 0.941     , 0.946408  , 0.574968  , 0.479664  ,\n",
      "       0.94024396, 0.93861204, 0.94247603, 0.94033396], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.57442397, 0.47344   , 0.935034  , 0.99853796, 0.685014  ,\n",
      "       0.935384  , 0.939896  , 0.574216  , 0.473232  , 0.934296  ,\n",
      "       0.93145204, 0.932664  , 0.93590206, 0.935176  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.904006  , 0.836362  , 0.94582397, 0.94538   , 0.94317603,\n",
      "       0.58258396, 0.485908  , 0.91828   , 0.91452   , 0.91041   ,\n",
      "       0.919556  , 0.591722  , 0.45261198, 0.434516  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.94397   , 0.944094  , 0.943564  , 0.945706  , 0.57538396,\n",
      "       0.481812  , 0.92585397, 0.94688797, 0.941444  , 1.1265221 ,\n",
      "       1.127918  , 0.604296  , 0.51041603, 0.94968   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.604296  , 0.51041603, 0.94968   , 0.944624  , 0.94387203,\n",
      "       0.94574   , 0.947016  , 0.574968  , 0.49128   , 0.947276  ,\n",
      "       0.948824  , 0.951836  , 0.94888   , 0.94924396], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.396632  , 0.84542   , 0.840988  , 0.849374  , 0.843996  ,\n",
      "       0.840372  , 0.514296  , 0.39888802, 0.83998   , 0.83426   ,\n",
      "       0.8147    , 0.80659604, 0.83964396, 0.5158    ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.98386794, 0.96911603, 0.968586  , 0.96566397, 0.613072  ,\n",
      "       0.49402   , 0.94882   , 0.90345   , 0.86440206, 0.925658  ,\n",
      "       0.896372  , 0.60983604, 0.48925   , 0.93494797], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.604976  , 0.492844  , 0.92081   , 0.92571604, 0.926454  ,\n",
      "       0.477876  , 0.926004  , 0.607668  , 0.4763    , 0.93488   ,\n",
      "       0.938116  , 0.938116  , 0.937056  , 0.94436   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.90252   , 0.889736  , 0.908536  , 0.90628   , 0.907256  ,\n",
      "       0.567832  , 0.440656  , 0.90176797, 0.90017205, 0.902956  ,\n",
      "       0.90424603, 0.90231204, 0.559592  , 0.40534398], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.494564  , 0.96911603, 0.967568  , 0.96911603, 0.97074795,\n",
      "       0.96913   , 0.615356  , 0.49562398, 0.973628  , 0.96911603,\n",
      "       0.96911603, 0.970204  , 0.96868604, 0.61220604], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.477508  , 0.93148   , 0.93098396, 0.93549603, 0.936944  ,\n",
      "       0.935576  , 0.570136  , 0.476448  , 0.938504  , 0.93215203,\n",
      "       0.93604   , 0.94257206, 0.94388205, 0.576488  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.944164  , 0.591524  , 0.49177   , 0.940736  , 0.918548  ,\n",
      "       0.92721397, 0.926296  , 0.93479604, 0.45683601, 0.436728  ,\n",
      "       0.896202  , 0.893658  , 0.899048  , 0.91224796], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.932584  , 0.93388   , 0.943784  , 0.584408  , 0.441312  ,\n",
      "       0.930436  , 0.932584  , 0.932584  , 0.933336  , 0.94160795,\n",
      "       0.584408  , 0.289064  , 0.35194397, 0.43768   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.936444  , 0.93756   , 0.93567604, 0.585932  , 0.46617398,\n",
      "       0.935914  , 0.90665   , 0.92825794, 0.940956  , 0.93326396,\n",
      "       0.583296  , 0.45880398, 0.936444  , 0.93318   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.81255203, 0.810348  , 0.81218797, 0.538688  , 0.46318   ,\n",
      "       0.81366795, 0.809916  , 0.81626   , 0.809444  , 0.811492  ,\n",
      "       0.53886   , 0.4519    , 0.81291604, 0.811492  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.54024804, 0.41122398, 0.88745   , 0.895714  , 0.89495   ,\n",
      "       0.861674  , 0.89517796, 0.54024804, 0.410136  , 0.83310604,\n",
      "       0.89350206, 0.889498  , 0.89401   , 0.940426  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.618092  , 0.60272   , 0.47521198, 0.9141    , 0.91566   ,\n",
      "       0.91798794, 1.013156  , 0.917572  , 0.607124  , 0.47446   ,\n",
      "       0.9141    , 0.914728  , 0.91395795, 0.92462796], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.47344   , 0.935034  , 0.99853796, 0.685014  , 0.935384  ,\n",
      "       0.939896  , 0.574216  , 0.473232  , 0.934296  , 0.93145204,\n",
      "       0.932664  , 0.93590206, 0.935176  , 0.574344  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.46318   , 0.81366795, 0.809916  , 0.81626   , 0.809444  ,\n",
      "       0.811492  , 0.53886   , 0.4519    , 0.81291604, 0.811492  ,\n",
      "       0.81299603, 0.810962  , 0.81202203, 0.53568   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.58439803, 0.45932   , 0.937196  , 0.93945205, 0.936444  ,\n",
      "       0.93756   , 0.93567604, 0.585932  , 0.46617398, 0.935914  ,\n",
      "       0.90665   , 0.92825794, 0.940956  , 0.93326396], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.583296  , 0.45826   , 0.935692  , 0.935914  , 0.939646  ,\n",
      "       0.93038   , 0.93738204, 0.582766  , 0.46664602, 0.93834203,\n",
      "       0.935356  , 0.932092  , 0.93784   , 0.936988  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.937016  , 0.943032  , 0.57442397, 0.47344   , 0.935034  ,\n",
      "       0.99853796, 0.685014  , 0.935384  , 0.939896  , 0.574216  ,\n",
      "       0.473232  , 0.934296  , 0.93145204, 0.932664  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.94542 , 0.947996, 0.942796, 0.60349 , 0.469948, 0.890574,\n",
      "       0.892864, 0.893696, 0.895716, 0.907486, 0.60557 , 0.474628,\n",
      "       0.925164, 0.917364], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.547016  , 0.418744  , 0.626128  , 0.892958  , 0.892506  ,\n",
      "       0.894314  , 0.886026  , 0.541     , 0.41205603, 0.887862  ,\n",
      "       0.892252  , 0.893394  , 0.89130604, 0.895932  ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.93857795, 0.937948  , 0.93494   , 0.935692  , 0.936444  ,\n",
      "       0.583296  , 0.45826   , 0.935692  , 0.935914  , 0.939646  ,\n",
      "       0.93038   , 0.93738204, 0.582766  , 0.46664602], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.932636  , 0.581692  , 0.45847398, 0.931004  , 0.932092  ,\n",
      "       0.936904  , 0.932092  , 0.93152   , 0.5847    , 0.4629    ,\n",
      "       0.930556  , 0.93659204, 0.93730795, 0.93663603], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.85075796, 0.546536  , 0.440992  , 0.854944  , 0.8313    ,\n",
      "       0.84162205, 0.87018   , 0.92115   , 0.56711197, 0.4716    ,\n",
      "       0.93216205, 0.93023604, 0.928396  , 0.92753   ], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.933446  , 0.941416  , 0.941     , 0.946408  , 0.574968  ,\n",
      "       0.479664  , 0.94024396, 0.93861204, 0.94247603, 0.94033396,\n",
      "       0.94537604, 0.582716  , 0.48225603, 0.95411795], dtype=float32)>>\n",
      "new iteration\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([0.96316   , 0.963832  , 0.969216  , 0.60942   , 0.49402   ,\n",
      "       0.967512  , 0.969016  , 0.96784794, 0.969546  , 0.973386  ,\n",
      "       0.614412  , 0.494564  , 0.97062   , 0.97062   ], dtype=float32)>>\n",
      "new iteration\n"
     ]
    }
   ],
   "source": [
    "for i in commuter_train:\n",
    "    print(i[1][0, 0, :].numpy)\n",
    "    print('new iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4e2f8f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.443208  , 0.34981802, 0.80536795, 0.804724  , 0.802554  ,\n",
       "       0.764166  , 0.777658  , 0.486704  , 0.363614  , 0.79706   ,\n",
       "       0.7955    , 0.793966  , 0.344518  , 0.288142  , 0.35942   ,\n",
       "       0.362026  , 0.80396396, 0.802948  , 0.79773396, 0.792576  ,\n",
       "       0.382896  , 0.49272   , 0.361444  , 0.780898  , 0.78344   ,\n",
       "       0.357708  , 0.737806  , 0.714888  , 0.49691802, 0.362318  ,\n",
       "       0.77778   , 0.603158  , 0.61511487, 0.76327   , 0.74922603,\n",
       "       0.4958    , 0.35984   , 0.74884   , 0.75616604, 0.740184  ,\n",
       "       0.76503396, 0.677056  , 0.475842  , 0.360298  ], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['commuter'].head(44).values/1E5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ee27c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step\n",
      "0.00041084472\n",
      "5.5993965e-10\n",
      "3.1179075e-05\n",
      "0.0019652548\n",
      "0.0007950299\n",
      "0.0008659619\n",
      "0.00012773777\n",
      "0.00023350689\n",
      "0.0016602537\n",
      "0.00010652963\n",
      "0.00034446447\n",
      "2.7973712e-05\n",
      "0.0005844618\n",
      "0.0020749806\n",
      "8.9359746e-05\n",
      "0.0002938011\n",
      "\n",
      "\n",
      "0.0005876022\n"
     ]
    }
   ],
   "source": [
    "testing_data = tf.data.Dataset.from_tensor_slices(df['commuter'][1847: 2577] / 1E5)\n",
    "\n",
    "\n",
    "def eval_seq2seq_model(model, data, forecast_length=1, seq_length=7, batch_size=1):\n",
    "    data = data.window(forecast_length+seq_length, drop_remainder=True)\n",
    "    data = data.flat_map(lambda x: x)\n",
    "    data = data.batch(forecast_length+seq_length)\n",
    "    #data = timeseries_window(data, forecast_length+seq_length)\n",
    "    data = data.map(lambda x: (x[:seq_length], x[seq_length:]))\n",
    "\n",
    "    data = data.batch(batch_size)\n",
    "    # Predict and keep only last sequence of prediction\n",
    "    prediction = tf.data.Dataset.from_tensor_slices(rnn_seq2seq.predict(data)[:, -1, :])\n",
    "\n",
    "    prediction = prediction.batch(batch_size)\n",
    "    data = tf.data.Dataset.zip(data, prediction)\n",
    "    mse = np.zeros(14, dtype=np.float32)\n",
    "    for i in data.as_numpy_iterator():\n",
    "        sequences, target = i[0]\n",
    "        pred = i[1]\n",
    "        mse = np.sum(np.square(pred - target), axis=0) / batch_size\n",
    "        mse += mse\n",
    "    return np.sum(mse)\n",
    "    #for i in data.as_numpy_iterator():\n",
    "    #    result = rnn_seq2seq(i[0][:, :, np.newaxis])\n",
    "    #    target = i[1][:, np.newaxis, :]\n",
    "    #    print(result[0, -1, :] - target[0, :, :])\n",
    "    #    print(np.sqrt(np.sum(np.square(result[:, -1, :] - target)) / batch_size / forecast_length))\n",
    "\n",
    "mse = eval_seq2seq_model(rnn_seq2seq_training, testing_data, forecast_length=14, seq_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7212c57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8760220e-04, 4.5989486e-04, 3.4316052e-03, 1.1808785e-02,\n",
       "       2.2307457e-03, 4.8437752e-04, 1.2193810e-04, 8.2763209e-04,\n",
       "       2.0214634e-06, 2.8416878e-04, 3.1612022e-03, 5.8806813e-03,\n",
       "       1.3787013e-03, 1.1862561e-03], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e215421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "493/493 [==============================] - 3s 2ms/step - loss: 0.2131\n",
      "Epoch 2/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.1121\n",
      "Epoch 3/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0919\n",
      "Epoch 4/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0881\n",
      "Epoch 5/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0871\n",
      "Epoch 6/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0866\n",
      "Epoch 7/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0862\n",
      "Epoch 8/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0859\n",
      "Epoch 9/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0856\n",
      "Epoch 10/10\n",
      "493/493 [==============================] - 1s 2ms/step - loss: 0.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f83c8841f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(None, 1)),\n",
    "    tf.keras.layers.LSTM(3, return_sequences=True)\n",
    "])\n",
    "test_rnn.compile(loss='mse', optimizer='adam')\n",
    "x_training_data = np.random.rand(500, 1)\n",
    "x_train = tf.data.Dataset.from_tensor_slices(x_training_data)\n",
    "x_train = timeseries_dataset_seq2seq(x_train)\n",
    "y_training_data = np.random.rand(500, 3)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_training_data)\n",
    "\n",
    "\n",
    "test_rnn.fit(x=x_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bf8dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 60, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rnn.predict(np.random.rand(1, 10, 1))\n",
    "np.random.rand(1, 60, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "25804b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67388077 0.18984745 0.61122116 0.31137044 0.50503867 0.18929037\n",
      " 0.61636287 0.97836272 0.70692446 0.79188471 0.11336993 0.01475838\n",
      " 0.83786145 0.50861334]\n",
      "[0.81867838 0.79164872 0.11088158 0.29023907 0.57815831 0.0342671\n",
      " 0.00434693 0.2741532  0.15625099 0.78368318 0.18649465 0.0013391\n",
      " 0.85996041 0.29445972]\n",
      "[0.01330934 0.24549398 0.08873156 0.71743076 0.21148537 0.72991601\n",
      " 0.66889605 0.83391747 0.81458398 0.35312731 0.35237431 0.73738273\n",
      " 0.96517253 0.52211691]\n",
      "[0.08045153 0.92695746 0.30384688 0.22169256 0.85231981 0.36898274\n",
      " 0.69632564 0.17785737 0.99774497 0.93419654 0.98740287 0.81108123\n",
      " 0.90829649 0.51305405]\n",
      "[0.23834562 0.90531048 0.00863958 0.08093868 0.22606262 0.85072973\n",
      " 0.22908413 0.73069026 0.762691   0.32499139 0.65763599 0.64558172\n",
      " 0.69650676 0.10202842]\n",
      "[0.60028532 0.07613098 0.38184849 0.11085824 0.82751313 0.58460833\n",
      " 0.13727838 0.87527711 0.51458954 0.46814201 0.28440379 0.12228945\n",
      " 0.7698344  0.23207313]\n",
      "[0.32205817 0.39806014 0.68102314 0.28397828 0.01403007 0.12466031\n",
      " 0.54509912 0.32188899 0.5034985  0.07103297 0.02632227 0.62627549\n",
      " 0.84521944 0.96162737]\n",
      "[0.44964945 0.96535731 0.87818486 0.18301416 0.01080452 0.61278645\n",
      " 0.3238817  0.61165894 0.64247133 0.05489187 0.58672332 0.8481531\n",
      " 0.56085074 0.71518759]\n",
      "[0.81144944 0.81255406 0.76585015 0.0167234  0.00834109 0.75603269\n",
      " 0.86140576 0.06015929 0.40342788 0.72729481 0.03530758 0.94190276\n",
      " 0.67229717 0.57643199]\n",
      "[0.64400356 0.13655128 0.8332986  0.0185449  0.26777481 0.27449127\n",
      " 0.28898543 0.72502415 0.09113105 0.92011646 0.67805378 0.75153067\n",
      " 0.29665466 0.10618037]\n",
      "[0.47346333 0.44613342 0.6044283  0.79513136 0.33243857 0.98734486\n",
      " 0.66060642 0.93425082 0.4561239  0.59600395 0.69138945 0.68268566\n",
      " 0.04714791 0.34924071]\n",
      "[0.54915037 0.82230529 0.64303598 0.73797224 0.09874984 0.06138457\n",
      " 0.2170812  0.61995817 0.52351431 0.83639597 0.25606677 0.94474034\n",
      " 0.00423285 0.36990968]\n",
      "[0.62916207 0.70845953 0.83946539 0.7509079  0.4371796  0.37972269\n",
      " 0.35942954 0.41287582 0.80661376 0.92173137 0.05422665 0.37877763\n",
      " 0.02521917 0.61325941]\n",
      "[0.02576389 0.88670677 0.54250339 0.10641117 0.34866735 0.76156822\n",
      " 0.30287355 0.17971638 0.04822514 0.28855145 0.30267054 0.5301505\n",
      " 0.13835105 0.55968984]\n",
      "[0.33798793 0.94066733 0.91183926 0.83931707 0.12657836 0.65554698\n",
      " 0.73708292 0.53919446 0.38122131 0.12838358 0.08115912 0.04670611\n",
      " 0.26665036 0.7523315 ]\n",
      "[0.71751975 0.44699908 0.4507161  0.02535093 0.53020273 0.82665169\n",
      " 0.39056484 0.04085058 0.44936695 0.11198516 0.59320776 0.64680055\n",
      " 0.48264001 0.09088077]\n",
      "[0.39052736 0.03771287 0.13764596 0.05873553 0.00851029 0.28863883\n",
      " 0.34525324 0.98827033 0.57798653 0.59622998 0.91635766 0.88961131\n",
      " 0.62788677 0.03113455]\n",
      "[0.83743507 0.87310166 0.21002915 0.02451076 0.87502626 0.09527334\n",
      " 0.80994109 0.46896117 0.43009102 0.06232755 0.62440147 0.96058492\n",
      " 0.40201056 0.10517127]\n",
      "[0.77084595 0.84287741 0.4210406  0.00367403 0.16589142 0.03233794\n",
      " 0.36606983 0.12638273 0.39014338 0.3828352  0.26918524 0.46302582\n",
      " 0.6690314  0.09478815]\n",
      "[0.44857359 0.54856402 0.9969665  0.02840385 0.61707052 0.9906487\n",
      " 0.08636966 0.93316015 0.37327439 0.03458469 0.96864453 0.45429053\n",
      " 0.66135642 0.82112224]\n",
      "[0.88896954 0.93742543 0.72018904 0.91407235 0.90929593 0.59886644\n",
      " 0.51157176 0.93264991 0.72604191 0.68102092 0.22363341 0.35087806\n",
      " 0.43813092 0.0841    ]\n",
      "[0.52491029 0.32967699 0.09620995 0.67936254 0.10820112 0.75912062\n",
      " 0.16849995 0.55112123 0.47437068 0.36422081 0.02548628 0.90185522\n",
      " 0.3896367  0.47442485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.24642  , 13.268541 , 11.237595 ,  7.1986403,  8.0593405,\n",
       "       10.96287  ,  9.327009 , 12.3163805, 11.230288 , 10.433632 ,\n",
       "        8.914517 , 12.7504015, 11.564948 ,  8.877827 ], dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(14, dtype=np.float32)\n",
    "\n",
    "for i in range(22):\n",
    "    b = np.random.rand(14)\n",
    "    a += b\n",
    "    print(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae57b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This blocks evaluates all possible keys in the nested dictionary \"wagon\" in compositions of one day\n",
    "\n",
    "properties_dict = dict()\n",
    "for train in k.json():\n",
    "    for journey in (train['journeySections']):\n",
    "        for wagon in journey['wagons']:\n",
    "            for i, prop in enumerate(wagon.keys()):\n",
    "                try:\n",
    "                    properties_dict[prop]\n",
    "                except:\n",
    "                    properties_dict[prop] = prop\n",
    "print(properties_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6376e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84644132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "session.add(bsp)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e2ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as w:\n",
    "    w.write('haha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c57c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
