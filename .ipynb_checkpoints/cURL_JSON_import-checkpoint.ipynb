{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a237bc7b",
   "metadata": {},
   "source": [
    "# Finish open rail analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2019c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e2d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function\n",
    "def underscore_lower_match(match):\n",
    "    return '_'+match.group(1).lower()\n",
    "\n",
    "def cURL(url, *options):\n",
    "    '''Function will call curl on the system. \n",
    "    \n",
    "    Parameters:\n",
    "    url: <string> URL to be called by cURL\n",
    "    *options: <string> optional arguments passed to cURL-call\n",
    "    \n",
    "    Returns: \n",
    "    os.system call (cURL command)\n",
    "    '''    \n",
    "    opt_string = str() #init string and concatenate all optinal arguments, seperator: whitespace\n",
    "    for i, val in enumerate(options):\n",
    "        opt_string += f'{val} '\n",
    "    # Call cURL command on system using concatenated string and url-string\n",
    "    return os.system(f'curl ' + opt_string + f'{url}')\n",
    "\n",
    "def mod_file_extension(file, extension='.gz'):\n",
    "    '''Function will replace the file's extension.\n",
    "    \n",
    "    Parameters:\n",
    "    file: <string> file name together with potential directory path\n",
    "    extension: <string> new file name extension (incl. dot) to be used. Default: \".gz\"\n",
    "    \n",
    "    Returns:\n",
    "    os.system call (mv file)\n",
    "    '''\n",
    "    split_string = file.split(sep='.') # splitting file name at \".\", which exclusively\n",
    "    output_file = split_string[0]+extension\n",
    "    return os.system(f'mv {file} {output_file}')\n",
    "\n",
    "def decompress_gz(file, extension='.json'):\n",
    "    '''Function decompresses archive and returns file path.\n",
    "    \n",
    "    Parameters:\n",
    "    file: <string> File to decompress\n",
    "    extension: <string> File extension (incl. dot) for decompressed file. Default: '.json'\n",
    "    \n",
    "    Returns:\n",
    "    <string> path and name of output file (composed of passed file and extension)\n",
    "    '''\n",
    "    split_string = file.split('.')\n",
    "    output_file = split_string[0]+extension\n",
    "    os.system(f'gzip -d -c {file} > {output_file}')\n",
    "    return output_file\n",
    "\n",
    "def delete_file(file):\n",
    "    '''\n",
    "    '''\n",
    "    return os.system(f'rm {file}')\n",
    "\n",
    "def tweak_wagons(data_raw):\n",
    "    '''Function partially flattens input file (json format) and customizes columns, see comments\n",
    "    \n",
    "    Parameters:\n",
    "    data_raw <json object> Data to process\n",
    "    \n",
    "    Returns: \n",
    "    <pandas DataFrame> DataFrame with one column per wagon, columns as specified below.\n",
    "    '''\n",
    "    df = (pd.json_normalize(data_raw, record_path=['journeySections', 'wagons'], # DataFrame with as many rows as \"wagons\"\n",
    "        meta=['trainNumber', # Add train number to DataFrame\n",
    "              'operatorShortCode', # Add short code of train operator to DataFrame\n",
    "              'trainCategory', # Add train category (such that \"IC\") to DataFrame\n",
    "              'trainType', # Add train type to DataFrame\n",
    "              'departureDate', # Add departure date to DataFrame\n",
    "              ['journeySection', 'totalLength'], # Add total length of train to DataFrame\n",
    "              ['journeySection', 'maximumSpeed'], # Add total speed column\n",
    "              ['journeySection', 'beginTimeTableRow', 'stationShortCode'], # Add station code of begin station\n",
    "              ['journeySection', 'endTimeTableRow', 'stationShortCode']], # Add station code of end station\n",
    "        sep='_') # use \"_\" to concatenate column names, when made up from several contributions (depth > 1)\n",
    "         )\n",
    "    if not ('luggage' in df.columns):\n",
    "        df = df.assign(luggage=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    if not ('playground' in df.columns):\n",
    "        df = df.assign(playground=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    if not ('video' in df.columns):\n",
    "        df = df.assign(video=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    if not ('disabled' in df.columns):\n",
    "        df = df.assign(disabled=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    if not ('catering' in df.columns):\n",
    "        df = df.assign(catering=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    if not ('pet' in df.columns):\n",
    "        df = df.assign(pet=pd.Series(index=df_wagons.index, dtype='bool', data=False))\n",
    "    return (df\n",
    "        .rename(axis='columns', mapper=lambda s: s.split('_')[-1]) # keep only clumn description of deepest level\n",
    "        # split all column names at capital letters and concatenate lower cased parts with \"_\"        \n",
    "        .rename(axis='columns', mapper=lambda s: re.sub(r'([A-Z])', underscore_lower_match, s).lower())\n",
    "        .rename(axis='columns', mapper={'length': 'length_cm'})\n",
    "        .assign(departure_date=lambda s: s.departure_date.astype('datetime64'), # Departure Date as Datetime type\n",
    "            # Assign data type given in documentation on rata.traffic.fi or appropriate one \n",
    "            train_number=lambda s: s.train_number.astype('int64'),\n",
    "            operator_short_code=lambda s: s.operator_short_code.astype('category'),\n",
    "            train_category=lambda s: s.train_category.astype('category'),\n",
    "            train_type=lambda s: s.train_type.astype('category'),\n",
    "            total_length=lambda s: s.total_length.astype('int32'),\n",
    "            maximum_speed=lambda s: s.maximum_speed.astype('int32'),\n",
    "            # For following bool columns, missing value means \"False\"\n",
    "            playground=lambda s: s.playground.fillna(value=False),\n",
    "            video=lambda s: s.video.fillna(value=False),\n",
    "            disabled=lambda s: s.disabled.fillna(value=False), \n",
    "            catering=lambda s: s.catering.fillna(value=False),\n",
    "            pet=lambda s: s.pet.fillna(value=False),\n",
    "            luggage=lambda s: s.luggage.fillna(value=False),\n",
    "            # Fill missing values of wagon type with \"unknow\" > 40% missing values, > 20 diff. wagons\n",
    "            wagon_type=lambda s: s.wagon_type.fillna(value='unknown')\n",
    "                .astype('category'))\n",
    "        .astype({'location': 'int32',\n",
    "                 'sales_number': 'int32',\n",
    "                 'length_cm': 'int32'})\n",
    ")\n",
    "\n",
    "def wagon_list(json_file):\n",
    "    '''Function takes one file, opens it and returns pandas DataFrame as specified in \"tweak_wagons\"\n",
    "    \n",
    "    Parameters:\n",
    "    json_file: <string> File path together with file name. File to process\n",
    "    \n",
    "    Returns:\n",
    "    <pandas DataFrame> DataFrame as specified in function \"tweak_wagons\" \n",
    "    '''\n",
    "    with open(json_file) as data:\n",
    "        return tweak_wagons(json.load(data))\n",
    "    \n",
    "def collect_compositions_of_day(date='2015-12-11', \n",
    "                                working_dir='/home/felbus/ml_for_physicists/temp/'):\n",
    "    '''Function collects composition information from API of \"rata.digitraffic.fi\" of specific day\n",
    "    \n",
    "    Parameters:\n",
    "    date <string> Date to collect data of \"yyyy-mm-dd\"\n",
    "    working_dir <string> Directory to temporarly store downloaded data in\n",
    "    '''\n",
    "    # compose url and file name information for call of cURL \n",
    "    url_compositions = 'https://rata.digitraffic.fi/api/v1/compositions/'\n",
    "    url = url_compositions + date\n",
    "    file_name = 'temp.gz'\n",
    "    data_dir = working_dir + file_name\n",
    "    # Call cURL\n",
    "    cURL(url, '-H \\'Accept-Encoding: gzip\\'', '-o', data_dir)\n",
    "    # Downloaded file is an archive, thus decompress it\n",
    "    file_decompressed = decompress_gz(data_dir)\n",
    "    # Turn data into DataFrame, that lists every wagon one time\n",
    "    df = wagon_list(file_decompressed)\n",
    "    # Delete temporary files\n",
    "    delete_file(data_dir)\n",
    "    delete_file(file_decompressed)\n",
    "    # Return DataFrame holding every wagon\n",
    "    return df\n",
    "\n",
    "def dates_between(date_begin, date_end):\n",
    "    '''Generator function that returns strings of dates.\n",
    "    \n",
    "    Parameters: \n",
    "    date_begin <string> First date in generator \"yyyy-mm-dd\"\n",
    "    date_end <string> Date to end generator, caution this date is exclusive! \"yyyy-mm-dd\"\n",
    "    \n",
    "    Returns:\n",
    "    Generator providing dates as strings \"yyyy-mm-dd\"\n",
    "    '''\n",
    "    date = pd.to_datetime(date_begin)\n",
    "    date_stop = pd.to_datetime(date_end)\n",
    "    while date < date_stop:\n",
    "        yield str(date.year)+'-'+f'{date.month:02d}'+'-'+f'{date.day:02d}'\n",
    "        date += pd.Timedelta(days=1)\n",
    "\n",
    "def wagon_list_to_total_length(wagons, groupby='train_category'):\n",
    "    '''Function transforms DataFrame by grouping by \"departure date\" and aggregate. Returned DataFrame will\n",
    "    hold cummulative length of wagons in meters.\n",
    "    \n",
    "    Parameters:\n",
    "    wagons <pandas DataFrame> DataFrame that holds at least columns \"departure_date\", \"length_cm\" and\n",
    "    aggregate\n",
    "    aggregate <string> Column of \"wagons\" to groupby\n",
    "    \n",
    "    Returns:\n",
    "    <pandas DataFrame> index = dates, columns = groupby of groupby-parameter\n",
    "    '''\n",
    "    return (wagons.assign(length_cm=lambda s: s.length_cm/100)\n",
    "            .groupby(['departure_date', groupby]).length_cm.sum().unstack())\n",
    "\n",
    "def collect_total_length(date_begin, date_end):\n",
    "    '''Function collects information about total length of train compositions for every date specified.\n",
    "    \n",
    "    Parameters:\n",
    "    date_begin <string> First date to collect data for \"yyyy-mm-dd\"\n",
    "    date_end <string> Last date (exclusive) to collect data for \"yyyy-mm-dd\"\n",
    "    \n",
    "    Returns:\n",
    "    <pandas DataFrame> Index: dates, Columns: train_categories, Values: total length [m]\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    for dates in dates_between(date_begin, date_end):\n",
    "        df_wagons = collect_compositions_of_day(date=dates)\n",
    "        df = pd.concat([df, wagon_list_to_total_length(df_wagons)])\n",
    "    df = (df.rename(axis='columns', mapper=lambda s: s.lower())\n",
    "            .rename(axis='columns', mapper=lambda s:s.replace('-', '_')))\n",
    "    return df\n",
    "\n",
    "def collect_wagon_list_period(date_begin, date_end):\n",
    "    '''Function collects information about train compositions for every date specified.\n",
    "    \n",
    "    Parameters:\n",
    "    date_begin <string> First date to collect data for \"yyyy-mm-dd\"\n",
    "    date_end <string> Last date (exclusive) to collect data for \"yyyy-mm-dd\"\n",
    "    \n",
    "    Returns:\n",
    "    <pandas DataFrame> Index: dates, Columns: train_categories, Values: total length [m]\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    for dates in dates_between(date_begin, date_end):\n",
    "        df_wagons = collect_compositions_of_day(date=dates)\n",
    "        df = pd.concat([df, df_wagons], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def save_to_feather(df, file):\n",
    "    '''Function saves DataFrame to feather file, resetting index first. Avoids problem with DateTime-Index.\n",
    "    \n",
    "    Parameters:\n",
    "    df <pandas DataFrame> DataFrame to save\n",
    "    file <string> File to save to\n",
    "    \n",
    "    Return:\n",
    "    None\n",
    "    '''\n",
    "    (df\n",
    "         .reset_index()\n",
    "         .to_feather(file)\n",
    "    )\n",
    "    return None\n",
    "    \n",
    "def load_from_feather(file):\n",
    "    '''Function laods pandas DataFrame from feather file. Expects column \"departure_date\" and will set it\n",
    "    as index.\n",
    "    \n",
    "    Parameters:\n",
    "    file <string> file (path+name) to load from\n",
    "    \n",
    "    Returns:\n",
    "    <pandas DataFrame> with column \"departure_date\" set as index\n",
    "    '''\n",
    "    df = pd.read_feather(file).set_index('departure_date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20710f22",
   "metadata": {},
   "source": [
    "## Loading and cleaning some data about train compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e7d8a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16571    0 16571    0     0  57380      0 --:--:-- --:--:-- --:--:-- 57538\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wagon_type</th>\n",
       "      <th>location</th>\n",
       "      <th>sales_number</th>\n",
       "      <th>length_cm</th>\n",
       "      <th>pet</th>\n",
       "      <th>playground</th>\n",
       "      <th>video</th>\n",
       "      <th>disabled</th>\n",
       "      <th>catering</th>\n",
       "      <th>luggage</th>\n",
       "      <th>train_number</th>\n",
       "      <th>operator_short_code</th>\n",
       "      <th>train_category</th>\n",
       "      <th>train_type</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>total_length</th>\n",
       "      <th>maximum_speed</th>\n",
       "      <th>station_short_code</th>\n",
       "      <th>station_short_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edb</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2640</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edfs</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wagon_type  location  sales_number  length_cm    pet  playground  video  \\\n",
       "0        Edb         1             5       2640   True       False  False   \n",
       "1       Edfs         2             4       2640  False        True   True   \n",
       "\n",
       "   disabled  catering  luggage  train_number operator_short_code  \\\n",
       "0     False     False    False             5                  vr   \n",
       "1      True     False    False             5                  vr   \n",
       "\n",
       "  train_category train_type departure_date  total_length  maximum_speed  \\\n",
       "0  Long-distance         IC     2015-12-25           152            200   \n",
       "1  Long-distance         IC     2015-12-25           152            200   \n",
       "\n",
       "  station_short_code station_short_code  \n",
       "0                HKI                JNS  \n",
       "1                HKI                JNS  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all train compositions of a specific day\n",
    "\n",
    "# Define URL for cURL GET \n",
    "url_compositions = 'https://rata.digitraffic.fi/api/v1/compositions/'\n",
    "date = '2015-12-25'\n",
    "# Define directory and file name to store received data\n",
    "data_directory = '/home/felbus/ml_for_physicists/temp/'\n",
    "file_name = 'test.gz'\n",
    "\n",
    "# Send cURL GET and decompressed received data.\n",
    "cURL(url_compositions+date, '-H \\'Accept-Encoding: gzip\\'', '-o', data_directory+file_name)\n",
    "file_decompressed = decompress_gz(data_directory+file_name)\n",
    "\n",
    "# Turn data into DataFrame, that lists every wagon one time.\n",
    "with open(file_decompressed) as data:\n",
    "    df_wagons1 = tweak_wagons(json.load(data))\n",
    "\n",
    "df_wagons1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9088e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 22179    0 22179    0     0  74099      0 --:--:-- --:--:-- --:--:-- 73930\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wagon_type</th>\n",
       "      <th>location</th>\n",
       "      <th>sales_number</th>\n",
       "      <th>length_cm</th>\n",
       "      <th>playground</th>\n",
       "      <th>video</th>\n",
       "      <th>disabled</th>\n",
       "      <th>catering</th>\n",
       "      <th>pet</th>\n",
       "      <th>luggage</th>\n",
       "      <th>train_number</th>\n",
       "      <th>operator_short_code</th>\n",
       "      <th>train_category</th>\n",
       "      <th>train_type</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>total_length</th>\n",
       "      <th>maximum_speed</th>\n",
       "      <th>station_short_code</th>\n",
       "      <th>station_short_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ed</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ed</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wagon_type  location  sales_number  length_cm  playground  video  disabled  \\\n",
       "0         Ed         1             6       2640       False  False     False   \n",
       "1         Ed         2             5       2640       False  False     False   \n",
       "\n",
       "   catering    pet  luggage  train_number operator_short_code train_category  \\\n",
       "0     False  False    False             1                  vr  Long-distance   \n",
       "1     False  False    False             1                  vr  Long-distance   \n",
       "\n",
       "  train_type departure_date  total_length  maximum_speed station_short_code  \\\n",
       "0         IC     2015-12-26           179            200                HKI   \n",
       "1         IC     2015-12-26           179            200                HKI   \n",
       "\n",
       "  station_short_code  \n",
       "0                JNS  \n",
       "1                JNS  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define URL for cURL GET \n",
    "url_compositions = 'https://rata.digitraffic.fi/api/v1/compositions/'\n",
    "date = '2015-12-26'\n",
    "# Define directory and file name to store received data\n",
    "data_directory = '/home/felbus/ml_for_physicists/temp/'\n",
    "file_name = 'test.gz'\n",
    "\n",
    "# Send cURL GET and decompressed received data.\n",
    "cURL(url_compositions+date, '-H \\'Accept-Encoding: gzip\\'', '-o', data_directory+file_name)\n",
    "file_decompressed = decompress_gz(data_directory+file_name)\n",
    "\n",
    "# Turn data into DataFrame, that lists every wagon one time.\n",
    "with open(file_decompressed) as data:\n",
    "    df_wagons2 = tweak_wagons(json.load(data))\n",
    "\n",
    "df_wagons2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c55bd2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_wagons1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_wagons2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/indexes/base.py:3904\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "pd.concat([df_wagons1, df_wagons2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2b28efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16571    0 16571    0     0  56747      0 --:--:-- --:--:-- --:--:-- 56945\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 22179    0 22179    0     0  76784      0 --:--:-- --:--:-- --:--:-- 77010\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_wagon_list \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_wagon_list_period\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2015-12-25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2015-12-27\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 215\u001b[0m, in \u001b[0;36mcollect_wagon_list_period\u001b[0;34m(date_begin, date_end)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dates \u001b[38;5;129;01min\u001b[39;00m dates_between(date_begin, date_end):\n\u001b[1;32m    214\u001b[0m     df_wagons \u001b[38;5;241m=\u001b[39m collect_compositions_of_day(date\u001b[38;5;241m=\u001b[39mdates)\n\u001b[0;32m--> 215\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_wagons\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/reshape/concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/indexes/base.py:3904\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "df_wagon_list = collect_wagon_list_period('2015-12-25', '2015-12-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae8ba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_feather(df_wagons, '/home/felbus/ml_for_physicists/data/test.fea')\n",
    "#load_from_feather('/home/felbus/ml_for_physicists/data/test.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ba4039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wagon_type</th>\n",
       "      <th>location</th>\n",
       "      <th>sales_number</th>\n",
       "      <th>length_cm</th>\n",
       "      <th>playground</th>\n",
       "      <th>video</th>\n",
       "      <th>disabled</th>\n",
       "      <th>catering</th>\n",
       "      <th>pet</th>\n",
       "      <th>luggage</th>\n",
       "      <th>train_number</th>\n",
       "      <th>operator_short_code</th>\n",
       "      <th>train_category</th>\n",
       "      <th>train_type</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>total_length</th>\n",
       "      <th>maximum_speed</th>\n",
       "      <th>station_short_code</th>\n",
       "      <th>station_short_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ed</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edfs</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2640</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERd</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edb</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2740</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>152</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5440</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10688</td>\n",
       "      <td>vr</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>HV</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>54</td>\n",
       "      <td>160</td>\n",
       "      <td>KV</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5440</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10693</td>\n",
       "      <td>vr</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>HV</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>54</td>\n",
       "      <td>120</td>\n",
       "      <td>RI</td>\n",
       "      <td>HL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5440</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10694</td>\n",
       "      <td>vr</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>HV</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>54</td>\n",
       "      <td>120</td>\n",
       "      <td>HL</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11661</td>\n",
       "      <td>vr</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>HV</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>ILR</td>\n",
       "      <td>KE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11662</td>\n",
       "      <td>vr</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>HV</td>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>KE</td>\n",
       "      <td>ILR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wagon_type  location  sales_number  length_cm  playground  video  \\\n",
       "0            Ed         1             5       2640       False  False   \n",
       "1          Edfs         2             4       2640        True   True   \n",
       "2           ERd         3             3       2640       False  False   \n",
       "3           Edb         4             2       2640       False  False   \n",
       "4           Edo         5             1       2740       False   True   \n",
       "...         ...       ...           ...        ...         ...    ...   \n",
       "5237          M         1             0       5440       False  False   \n",
       "5238          M         1             0       5440       False  False   \n",
       "5239          M         1             0       5440       False  False   \n",
       "5240    unknown         1             0       7520       False  False   \n",
       "5241    unknown         1             0       7520       False  False   \n",
       "\n",
       "      disabled  catering    pet  luggage  train_number operator_short_code  \\\n",
       "0        False     False  False    False             1                  vr   \n",
       "1         True     False  False    False             1                  vr   \n",
       "2        False      True  False    False             1                  vr   \n",
       "3        False     False   True    False             1                  vr   \n",
       "4        False     False   True    False             1                  vr   \n",
       "...        ...       ...    ...      ...           ...                 ...   \n",
       "5237     False     False  False    False         10688                  vr   \n",
       "5238     False     False  False    False         10693                  vr   \n",
       "5239     False     False  False    False         10694                  vr   \n",
       "5240     False     False  False    False         11661                  vr   \n",
       "5241     False     False  False    False         11662                  vr   \n",
       "\n",
       "     train_category train_type departure_date  total_length  maximum_speed  \\\n",
       "0     Long-distance         IC     2015-12-15           152            200   \n",
       "1     Long-distance         IC     2015-12-15           152            200   \n",
       "2     Long-distance         IC     2015-12-15           152            200   \n",
       "3     Long-distance         IC     2015-12-15           152            200   \n",
       "4     Long-distance         IC     2015-12-15           152            200   \n",
       "...             ...        ...            ...           ...            ...   \n",
       "5237       Commuter         HV     2015-12-16            54            160   \n",
       "5238       Commuter         HV     2015-12-16            54            120   \n",
       "5239       Commuter         HV     2015-12-16            54            120   \n",
       "5240       Commuter         HV     2015-12-16            75            160   \n",
       "5241       Commuter         HV     2015-12-16            75            160   \n",
       "\n",
       "     station_short_code station_short_code  \n",
       "0                   HKI                JNS  \n",
       "1                   HKI                JNS  \n",
       "2                   HKI                JNS  \n",
       "3                   HKI                JNS  \n",
       "4                   HKI                JNS  \n",
       "...                 ...                ...  \n",
       "5237                 KV                 RI  \n",
       "5238                 RI                 HL  \n",
       "5239                 HL                 RI  \n",
       "5240                ILR                 KE  \n",
       "5241                 KE                ILR  \n",
       "\n",
       "[5242 rows x 19 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wagon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f5cfd86",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'luggage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/_libs/index.pyx:162\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/_libs/index.pyx:203\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/_libs/index.pyx:211\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/_libs/index.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'luggage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m col \u001b[38;5;241m=\u001b[39m df_debug2\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m----> 2\u001b[0m df_debug\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{s: df_debug[s] \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col})\n",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m col \u001b[38;5;241m=\u001b[39m df_debug2\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m----> 2\u001b[0m df_debug\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{s: \u001b[43mdf_debug\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col})\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/ml_for_physicists/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'luggage'"
     ]
    }
   ],
   "source": [
    "col = df_debug2.columns\n",
    "df_debug.assign(**{s: df_debug[s] if s in col else pd.Series() for s in col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1e28a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wagon_type', 'location', 'sales_number', 'length_cm', 'playground',\n",
       "       'video', 'disabled', 'catering', 'pet', 'luggage', 'train_number',\n",
       "       'operator_short_code', 'train_category', 'train_type', 'departure_date',\n",
       "       'total_length', 'maximum_speed', 'station_short_code',\n",
       "       'station_short_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2643a1db",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd62caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing data in DataFrame? False\n"
     ]
    }
   ],
   "source": [
    "# Any missing values left\n",
    "print(f'Any missing data in DataFrame? {df_wagons.isna().any().any()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db1062b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>train_category</th>\n",
       "      <th>Commuter</th>\n",
       "      <th>Long-distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departure_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-12</th>\n",
       "      <td>94772.0</td>\n",
       "      <td>43830.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "train_category  Commuter  Long-distance\n",
       "departure_date                         \n",
       "2019-04-12       94772.0       43830.54"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wagon_list_to_total_length(df_wagons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b461b82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wagon_type</th>\n",
       "      <th>location</th>\n",
       "      <th>sales_number</th>\n",
       "      <th>length_cm</th>\n",
       "      <th>playground</th>\n",
       "      <th>video</th>\n",
       "      <th>disabled</th>\n",
       "      <th>catering</th>\n",
       "      <th>pet</th>\n",
       "      <th>luggage</th>\n",
       "      <th>train_number</th>\n",
       "      <th>operator_short_code</th>\n",
       "      <th>train_category</th>\n",
       "      <th>train_type</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>total_length</th>\n",
       "      <th>maximum_speed</th>\n",
       "      <th>station_short_code</th>\n",
       "      <th>station_short_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ed</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ed</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eds</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2640</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERd</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edb</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Edo</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2740</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>IC</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>179</td>\n",
       "      <td>200</td>\n",
       "      <td>HKI</td>\n",
       "      <td>JNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sm3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2814</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>JNS</td>\n",
       "      <td>HKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMH</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>JNS</td>\n",
       "      <td>HKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TTC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2590</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>JNS</td>\n",
       "      <td>HKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TT</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2590</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>vr</td>\n",
       "      <td>Long-distance</td>\n",
       "      <td>S</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>JNS</td>\n",
       "      <td>HKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wagon_type  location  sales_number  length_cm  playground  video  disabled  \\\n",
       "0         Ed         1             6       2640       False  False     False   \n",
       "1         Ed         2             5       2640       False  False     False   \n",
       "2        Eds         3             4       2640        True   True      True   \n",
       "3        ERd         4             3       2640       False  False     False   \n",
       "4        Edb         5             2       2640       False  False     False   \n",
       "5        Edo         6             1       2740       False   True     False   \n",
       "6        Sm3         1             1       2814       False  False     False   \n",
       "7        CMH         2             2       2590       False  False      True   \n",
       "8        TTC         3             3       2590       False  False     False   \n",
       "9         TT         4             4       2590       False  False     False   \n",
       "\n",
       "   catering    pet  luggage  train_number operator_short_code train_category  \\\n",
       "0     False  False    False             1                  vr  Long-distance   \n",
       "1     False  False    False             1                  vr  Long-distance   \n",
       "2     False  False    False             1                  vr  Long-distance   \n",
       "3      True  False    False             1                  vr  Long-distance   \n",
       "4     False   True    False             1                  vr  Long-distance   \n",
       "5     False   True    False             1                  vr  Long-distance   \n",
       "6     False  False    False             2                  vr  Long-distance   \n",
       "7     False  False    False             2                  vr  Long-distance   \n",
       "8      True  False    False             2                  vr  Long-distance   \n",
       "9     False  False    False             2                  vr  Long-distance   \n",
       "\n",
       "  train_type departure_date  total_length  maximum_speed station_short_code  \\\n",
       "0         IC     2019-04-12           179            200                HKI   \n",
       "1         IC     2019-04-12           179            200                HKI   \n",
       "2         IC     2019-04-12           179            200                HKI   \n",
       "3         IC     2019-04-12           179            200                HKI   \n",
       "4         IC     2019-04-12           179            200                HKI   \n",
       "5         IC     2019-04-12           179            200                HKI   \n",
       "6          S     2019-04-12           160            220                JNS   \n",
       "7          S     2019-04-12           160            220                JNS   \n",
       "8          S     2019-04-12           160            220                JNS   \n",
       "9          S     2019-04-12           160            220                JNS   \n",
       "\n",
       "  station_short_code  \n",
       "0                JNS  \n",
       "1                JNS  \n",
       "2                JNS  \n",
       "3                JNS  \n",
       "4                JNS  \n",
       "5                JNS  \n",
       "6                HKI  \n",
       "7                HKI  \n",
       "8                HKI  \n",
       "9                HKI  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wagons.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfda4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>train_category</th>\n",
       "      <th>Commuter</th>\n",
       "      <th>Long-distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departure_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-12</th>\n",
       "      <td>9477200</td>\n",
       "      <td>4383054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "train_category  Commuter  Long-distance\n",
       "departure_date                         \n",
       "2019-04-12       9477200        4383054"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wagons.groupby(['departure_date', 'train_category']).length_cm.sum().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce64a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wagons.groupby(['departure_date', 'train_category']).length_cm.sum().unstack().reset_index().to_feather('test.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecf6c28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-12 00:00:00 \n",
      "\n",
      "2015-12-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date = pd.to_datetime('2015-12-12')\n",
    "print(date, '\\n')\n",
    "date_next = date + pd.Timedelta(days=1)\n",
    "print(date_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e24a056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-12-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    date = pd.to_datetime('2015-12-11')\n",
    "    num = 0\n",
    "    while num < 10:\n",
    "        yield date\n",
    "        num += 1\n",
    "        date \n",
    "\n",
    "for i in infinite_sequence():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4ea31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
